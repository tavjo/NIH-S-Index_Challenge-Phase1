{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findability Demonstration Notebook (parameterisable via Papermill)\n",
    "=================================================================\n",
    "\n",
    "This notebook ingests a CSV of identifiers (DOIs, repository URLs, or\n",
    "accession numbers), resolves each to a canonical landing‑page URL, issues an\n",
    "HTTP GET request with aiohttp, and assigns a binary *Findability* score based\n",
    "on the response status (1 = 2xx, 0 = otherwise).  Results are saved to a CSV\n",
    "inside `reports/` and displayed inline.\n",
    "\n",
    "*Prerequisites*\n",
    "---------------\n",
    "```bash\n",
    "pip install aiohttp pandas python-dotenv nbconvert papermill\n",
    "```\n",
    "\n",
    "*Execution (CLI)*\n",
    "----------------\n",
    "```bash\n",
    "papermill notebooks/findability_demo.ipynb \\\n",
    "          notebooks/output.ipynb \\\n",
    "          -p csv_path data/sample_identifiers.csv \\\n",
    "          -p output_dir reports\n",
    "\n",
    "jupyter nbconvert --to html notebooks/output.ipynb --output reports/latest.html\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('findability_demo.log', 'a')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [parameters]\n",
    "# Papermill will inject values here; defaults are for local runs\n",
    "csv_path = os.path.join(project_root,\"data/sample_identifiers.csv\")  # Path to input CSV\n",
    "output_dir = os.path.join(project_root, \"reports\")  # Directory to write outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Literal, Tuple, Optional\n",
    "\n",
    "import aiohttp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOI_REGEX = re.compile(r\"^10\\.\\d{4,9}/\\S+$\", re.IGNORECASE)\n",
    "HTTP_REGEX = re.compile(r\"^https?://\", re.IGNORECASE)\n",
    "# Mapping of *accession prefix* -> *landing‑page URL template*.\n",
    "ACCESSION_TEMPLATES = {\n",
    "    # NCBI resources\n",
    "    \"GSE\": \"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={acc}\",  # GEO Series\n",
    "    \"GSM\": \"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={acc}\",  # GEO Sample\n",
    "    \"SRR\": \"https://www.ncbi.nlm.nih.gov/sra/{acc}\",                     # SRA Run\n",
    "    \"SRX\": \"https://www.ncbi.nlm.nih.gov/sra/{acc}\",                     # SRA Experiment\n",
    "    \"SRP\": \"https://www.ncbi.nlm.nih.gov/sra/{acc}\",                     # SRA Project\n",
    "    \"NC_\": \"https://www.ncbi.nlm.nih.gov/nuccore/{acc}\",                 # GenBank RefSeq\n",
    "    # EMBL‑EBI resources\n",
    "    \"ERR\": \"https://www.ebi.ac.uk/ena/browser/view/{acc}\",               # ENA Run\n",
    "    \"ERP\": \"https://www.ebi.ac.uk/ena/browser/view/{acc}\",               # ENA Project\n",
    "    \"ENCSR\": \"https://www.encodeproject.org/experiments/{acc}/\",          # ENCODE\n",
    "    # Proteomics / Expression / Other\n",
    "    \"E-\": \"https://www.ebi.ac.uk/arrayexpress/experiments/{acc}\",        # ArrayExpress (prefixes E-MTAB‑, E-GEOD‑…)\n",
    "    \"PXD\": \"https://www.ebi.ac.uk/pride/archive/projects/{acc}\",        # PRIDE dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_type(identifier: str) -> Literal[\"doi\", \"url\", \"accession\"]:\n",
    "    \"\"\"Classify identifier string.\"\"\"\n",
    "    logger.info(f\"Detecting type for identifier: {identifier}\")\n",
    "    if HTTP_REGEX.match(identifier):\n",
    "        return \"URL\"\n",
    "    if DOI_REGEX.match(identifier):\n",
    "        return \"DOI\"\n",
    "    return \"Accession\"\n",
    "\n",
    "\n",
    "async def resolve_doi(doi: str, session: aiohttp.ClientSession) -> str | None:\n",
    "    \"\"\"Resolve DOI to canonical URL using Crossref.\"\"\"\n",
    "    logger.info(f\"Resolving DOI: {doi}\")\n",
    "    api_url = f\"https://api.crossref.org/works/{doi}\"\n",
    "    try:\n",
    "        async with session.get(api_url, timeout=10) as resp:\n",
    "            if resp.status == 200:\n",
    "                data = await resp.json()\n",
    "                resolved_url = data.get(\"message\", {}).get(\"URL\")\n",
    "                logger.info(f\"Resolved DOI: {resolved_url}\")\n",
    "                return resolved_url\n",
    "    except Exception:\n",
    "        logger.error(f\"Error resolving DOI: {doi}\")\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def resolve_accession(acc: str) -> Optional[str]:\n",
    "    \"\"\"Return landing‑page URL for supported accession prefixes.\n",
    "\n",
    "    The function checks `ACCESSION_TEMPLATES` for the *longest* matching prefix\n",
    "    (allowing multi‑char keys like \"ENCSR\" or \"NC_\"), then formats the URL. If\n",
    "    no prefix matches, `None` is returned so the caller can skip scoring.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Resolving accession: {acc}\")\n",
    "    try:\n",
    "        for prefix in sorted(ACCESSION_TEMPLATES, key=len, reverse=True):\n",
    "            if acc.startswith(prefix):\n",
    "                template = ACCESSION_TEMPLATES[prefix]\n",
    "                resolved_url = template.format(acc=acc)\n",
    "                logger.info(f\"Resolved accession: {resolved_url}\")\n",
    "                return resolved_url\n",
    "    except Exception:\n",
    "        logger.error(f\"Error resolving accession: {acc}\")\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "async def fetch_status(\n",
    "    session: aiohttp.ClientSession, url: str\n",
    ") -> Tuple[int | None, str | None, float]:\n",
    "    \"\"\"GET `url` and return (status, final_url, response_time_s).\"\"\"\n",
    "    logger.info(f\"Fetching status for URL: {url}\")\n",
    "    start = time.perf_counter()\n",
    "    try:\n",
    "        async with session.get(url, allow_redirects=True, timeout=10) as resp:\n",
    "            status = resp.status\n",
    "            final_url = str(resp.url)\n",
    "            logger.info(f\"Fetched status: {status}, final URL: {final_url}\")\n",
    "    except Exception:\n",
    "        logger.error(f\"Error fetching status for URL: {url}\")\n",
    "        status = None\n",
    "        final_url = None\n",
    "    duration = time.perf_counter() - start\n",
    "    return status, final_url, duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def score_identifiers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logger.info(\"Starting score_identifiers\")\n",
    "    async def _placeholder_task():\n",
    "    # This is a simple coroutine that returns the desired default tuple\n",
    "        return (None, None, 0.0)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # First pass – resolve DOIs and accessions to URLs\n",
    "        resolved: list[str | None] = []\n",
    "        for ident, typ in zip(df[\"Asset\"], df[\"AssetType\"]):\n",
    "            if typ == \"DOI\":\n",
    "                url = await resolve_doi(ident, session)\n",
    "            elif typ == \"Accession\":\n",
    "                url = resolve_accession(ident)\n",
    "            else:  # url\n",
    "                url = ident\n",
    "            resolved.append(url)\n",
    "        df[\"resolved_url\"] = resolved\n",
    "\n",
    "        # Second pass – probe landing pages\n",
    "        # tasks = [fetch_status(session, url) if url else (None, None, 0.0) for url in resolved]\n",
    "        tasks = [fetch_status(session, url) if url else _placeholder_task() for url in resolved]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        logger.info(\"Completed fetch_status\")\n",
    "    statuses, finals, times = zip(*results)\n",
    "    df[\"http_status\"] = statuses\n",
    "    df[\"final_url\"] = finals\n",
    "    df[\"response_s\"] = times\n",
    "    df[\"findable\"] = [1 if 200 <= (s or 0) < 300 else 0 for s in statuses]\n",
    "    logger.info(\"Completed score_identifiers\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main execution block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 16:53:28,155 - __main__ - INFO - Starting pipeline\n",
      "2025-05-20 16:53:28,160 - __main__ - INFO - Starting score_identifiers\n",
      "2025-05-20 16:53:28,165 - __main__ - INFO - Resolving DOI: 10.5061/dryad.4j0zpc8p9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 16:53:28,284 - __main__ - INFO - Resolving DOI: 10.6084/m9.figshare.6025748\n",
      "2025-05-20 16:53:28,316 - __main__ - INFO - Fetching status for URL: https://zenodo.org/record/7673768\n",
      "2025-05-20 16:53:28,317 - __main__ - INFO - Fetching status for URL: https://openneuro.org/datasets/ds004470/about\n",
      "2025-05-20 16:53:28,319 - __main__ - INFO - Fetching status for URL: NC_045512\n",
      "2025-05-20 16:53:28,320 - __main__ - ERROR - Error fetching status for URL: NC_045512\n",
      "2025-05-20 16:53:28,428 - __main__ - INFO - Fetched status: 200, final URL: https://openneuro.org/datasets/ds004470/about\n",
      "2025-05-20 16:53:30,895 - __main__ - INFO - Fetched status: 200, final URL: https://zenodo.org/records/7673769\n",
      "2025-05-20 16:53:30,897 - __main__ - INFO - Completed fetch_status\n",
      "2025-05-20 16:53:30,900 - __main__ - INFO - Completed score_identifiers\n",
      "2025-05-20 16:53:30,901 - __main__ - INFO - Completed pipeline\n",
      "2025-05-20 16:53:30,902 - __main__ - INFO - Saving results\n",
      "2025-05-20 16:53:30,907 - __main__ - INFO - Results written to reports/findability_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repo</th>\n",
       "      <th>Asset</th>\n",
       "      <th>AssetType</th>\n",
       "      <th>resolved_url</th>\n",
       "      <th>http_status</th>\n",
       "      <th>final_url</th>\n",
       "      <th>response_s</th>\n",
       "      <th>findable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zenodo</td>\n",
       "      <td>https://zenodo.org/record/7673768</td>\n",
       "      <td>URL</td>\n",
       "      <td>https://zenodo.org/record/7673768</td>\n",
       "      <td>200.0</td>\n",
       "      <td>https://zenodo.org/records/7673769</td>\n",
       "      <td>2.580201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenNeuro</td>\n",
       "      <td>https://openneuro.org/datasets/ds004470/about</td>\n",
       "      <td>URL</td>\n",
       "      <td>https://openneuro.org/datasets/ds004470/about</td>\n",
       "      <td>200.0</td>\n",
       "      <td>https://openneuro.org/datasets/ds004470/about</td>\n",
       "      <td>0.111066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dryad</td>\n",
       "      <td>10.5061/dryad.4j0zpc8p9</td>\n",
       "      <td>DOI</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Figshare</td>\n",
       "      <td>10.6084/m9.figshare.6025748</td>\n",
       "      <td>DOI</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GenBank</td>\n",
       "      <td>NC_045512</td>\n",
       "      <td>Accession</td>\n",
       "      <td>NC_045512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Repo                                          Asset   AssetType  \\\n",
       "0     Zenodo              https://zenodo.org/record/7673768         URL   \n",
       "1  OpenNeuro  https://openneuro.org/datasets/ds004470/about         URL   \n",
       "2      Dryad                        10.5061/dryad.4j0zpc8p9         DOI   \n",
       "3   Figshare                    10.6084/m9.figshare.6025748         DOI   \n",
       "4    GenBank                                      NC_045512  Accession    \n",
       "\n",
       "                                    resolved_url  http_status  \\\n",
       "0              https://zenodo.org/record/7673768        200.0   \n",
       "1  https://openneuro.org/datasets/ds004470/about        200.0   \n",
       "2                                           None          NaN   \n",
       "3                                           None          NaN   \n",
       "4                                      NC_045512          NaN   \n",
       "\n",
       "                                       final_url  response_s  findable  \n",
       "0             https://zenodo.org/records/7673769    2.580201         1  \n",
       "1  https://openneuro.org/datasets/ds004470/about    0.111066         1  \n",
       "2                                           None    0.000000         0  \n",
       "3                                           None    0.000000         0  \n",
       "4                                           None    0.000905         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure output directory exists\n",
    "out_dir = Path(output_dir)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read input\n",
    "input_df = pd.read_csv(csv_path)\n",
    "if \"AssetType\" not in input_df.columns:\n",
    "    input_df[\"AssetType\"] = input_df[\"Asset\"].apply(detect_type)\n",
    "\n",
    "# Run pipeline\n",
    "logger.info(\"Starting pipeline\")\n",
    "result_df = await score_identifiers(input_df.copy())\n",
    "logger.info(\"Completed pipeline\")\n",
    "\n",
    "# Save results\n",
    "logger.info(\"Saving results\")\n",
    "result_csv = out_dir / \"findability_results.csv\"\n",
    "result_df.to_csv(result_csv, index=False)\n",
    "logger.info(f\"Results written to {result_csv.relative_to(Path(project_root))}\")\n",
    "# Display\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Findability summary:\n",
      "                                         Asset  findable\n",
      "            https://zenodo.org/record/7673768         1\n",
      "https://openneuro.org/datasets/ds004470/about         1\n",
      "                      10.5061/dryad.4j0zpc8p9         0\n",
      "                  10.6084/m9.figshare.6025748         0\n",
      "                                    NC_045512         0\n"
     ]
    }
   ],
   "source": [
    "summary = result_df[[\"Asset\", \"findable\"]]\n",
    "print(\"\\nFindability summary:\\n\", summary.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
